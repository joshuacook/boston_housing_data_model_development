{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n",
      "/Users/joshuacook/src/scikit/scikit-learn/sklearn/cross_validation.py:42: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/joshuacook/src/scikit/scikit-learn/sklearn/grid_search.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "import seaborn\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully shuffled and split the data!\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "city_data = datasets.load_boston()\n",
    "housing_prices = city_data.target\n",
    "housing_features = city_data.data\n",
    "def shuffle_split_data(X, y):\n",
    "    \"\"\" Shuffles and splits data into 70% training and 30% testing subsets,\n",
    "        then returns the training and testing subsets. \"\"\"\n",
    "\n",
    "    # Shuffle and split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.7)\n",
    "\n",
    "    # Return the training and testing data subsets\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "# Test shuffle_split_data\n",
    "try:\n",
    "    X_train, y_train, X_test, y_test = shuffle_split_data(housing_features, housing_prices)\n",
    "    print \"Successfully shuffled and split the data!\"\n",
    "except:\n",
    "    print \"Something went wrong with shuffling and splitting the data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Performance Metric\n",
    "performance_metric = mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the features and labels from the Boston housing data\n",
    "X, y = city_data.data, city_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup a Decision Tree Regressor\n",
    "# GridSearchCV refers to this as its estimator\n",
    "# will be reg.estimator\n",
    "regressor = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters to be grid-searched over\n",
    "# will be reg.param_grid\n",
    "parameters = {'max_depth':(1,2,3,4,5,6,7,8,9,10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Performance Metric to be used\n",
    "# will be reg.scoring\n",
    "performance_metric_scorer = make_scorer(performance_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV object\n",
    "reg = GridSearchCV(regressor, parameters, scoring=performance_metric_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg.refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the learner to the training data\n",
    "print \"Final Model: \"\n",
    "print reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"best estimator:\\t{0}\".format(reg.best_estimator_)\n",
    "print \"best score:\\t{0}\".format(reg.best_score_)\n",
    "print \"best params:\\t{0}\".format(reg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the learner to the training data\n",
    "print \"Final Model: \"\n",
    "print reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"best estimator:\\t{0}\".format(reg.best_estimator_)\n",
    "print \"best score:\\t{0}\".format(reg.best_score_)\n",
    "print \"best params:\\t{0}\".format(reg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the learner to the training data\n",
    "print \"Final Model: \"\n",
    "print reg.fit(X, y)\n",
    "\n",
    "# Use the model to predict the output of a particular sample\n",
    "x = [11.95, 0.00, 18.100, 0, 0.6590, 5.6090, 90.00, 1.385, 24, 680.0, 20.20, 332.09, 12.13]\n",
    "y = reg.predict(x)\n",
    "print \"House: \" + str(x)\n",
    "print \"Prediction: \" + str(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Model Prediction\n",
    "\n",
    "- *Model makes predicted housing price with detailed model parameters (max depth). Note due to the small randomization of the code it is recommended to run the program several times to identify the most common/reasoable price/model complexity.*\n",
    "- *Compare prediction to earlier statistics and make a case if you think it is a valid model.*\n",
    "\n",
    "  The final prediction is run against this data point and returns the shown value.\n",
    "  \n",
    "  ```\n",
    "  House: [11.95, 0.0, 18.1, 0, 0.659, 5.609, 90.0, 1.385, 24, 680.0, 20.2, 332.09, 12.13]\n",
    "  Prediction: [ 21.62974359]\n",
    "  ```\n",
    "  \n",
    "  It is difficult to look at the original data set and speculate as the validity of this answer. As humans, we have little intuition for an 11-dimensional domain. That said, the process throuch which we generated this response was a reasonable one, involving both cross-validation and grid search. As such, I have a high degree of faith in this response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
